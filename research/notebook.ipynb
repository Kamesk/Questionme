{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "import numpy as np\n",
        "import re\n",
        "from langchain.schema import Document\n",
        "from langchain.llms import CTransformers\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import RetrievalQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#Importing all documents from the folder - artifacts and cleaning - /n removed, - replaced. \n",
        "path_to_pdfs = (r\"D:\\LLM\\projects\\Questionme\\artifacts\")\n",
        "loader = PyPDFDirectoryLoader(path_to_pdfs)\n",
        "pdf_documents = loader.load()\n",
        "\n",
        "def cleanup(document):\n",
        "    document = document.replace('\\n', ' ')\n",
        "    document = document.replace('-', '')\n",
        "    document = ' '.join(document.split())\n",
        "    document = re.sub(r'\\n+', ' ', document)\n",
        "    return document\n",
        "\n",
        "cleaned_documents = [cleanup(doc.page_content) for doc in pdf_documents]\n",
        "cleaned_document_objects = [Document(page_content=cleaned_text, metadata=doc.metadata) \n",
        "                             for cleaned_text, doc in zip(cleaned_documents, pdf_documents)]\n",
        "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=100)\n",
        "final_documents=text_splitter.split_documents(cleaned_document_objects)\n",
        "texts = [doc.page_content for doc in final_documents]\n",
        "text = texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "109"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = CTransformers(\n",
        "    model=r\"D:\\LLM\\models\\llama-2-7b-chat.ggmlv3.q8_0.bin\",\n",
        "    model_type=\"llama\",\n",
        "    config={'max_new_tokens': 300, 'temperature': 0.03,'context_length': 1000}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Jarviz_92\\anaconda3\\envs\\llm_env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "huggingface_embeddings=HuggingFaceBgeEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",      #sentence-transformers/all-MiniLM-l6-v2\n",
        "    model_kwargs={'device':'cpu'},\n",
        "    encode_kwargs={'normalize_embeddings':True})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.06778146  0.01100297  0.02574205 ...  0.00751806  0.06441373\n",
            "  -0.03051739]\n",
            " [-0.0693738  -0.02106547 -0.03994767 ... -0.00298001  0.05587736\n",
            "   0.04344444]\n",
            " [-0.03051266  0.08318012 -0.02475407 ... -0.06984834  0.04987878\n",
            "   0.01845735]\n",
            " ...\n",
            " [ 0.05832506  0.07038648  0.02622284 ...  0.07168836 -0.01516775\n",
            "  -0.02078729]\n",
            " [ 0.08588448  0.01911633  0.0015234  ...  0.04203937  0.02636152\n",
            "  -0.02784703]\n",
            " [-0.01472853 -0.00520878 -0.00508864 ...  0.07673403 -0.00523054\n",
            "  -0.04715177]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "embeddings = [huggingface_embeddings.embed_query(text) for text in texts]\n",
        "embeddings_array = np.array(embeddings)\n",
        "print(embeddings_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "vectorstore = FAISS.from_documents(final_documents, huggingface_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: The level of fixed penalty notices (FPNs) is set by local authorities, which includes unitary authorities, county councils, metropolitan district councils, and London Boroughs. Although in practice, some of these may have an agency agreement with city or district councils to act on their behalf on traffic matters.\n",
            "\n",
            "Please note that the information provided is based on the Road Traffic Act 1991 and other relevant legislation, but it is not a substitute for legal advice. If you are unsure about any aspect of parking rules, penalties, or fixed penalty details, please consult an updated and correct source or seek the advice of a trustworthy solicitor.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Define the prompt template\n",
        "template = \"\"\"\n",
        "You are an expert in UK parking rules, penalties, and fixed penalty details. Answer the question precisely. If you're not 100 percent sure of the answer, respond with 'not sure' and request the user to check updated and correct information or reach a trustworthy solicitor.\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "qa_prompt = PromptTemplate(template=template, input_variables=['context', 'question'])\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={'k': 2})\n",
        "\n",
        "chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type='stuff',\n",
        "    retriever=retriever,\n",
        "    return_source_documents=False,\n",
        "    chain_type_kwargs={'prompt': qa_prompt}\n",
        ")\n",
        "\n",
        "user_input = \"Who sets the level of FPN's\"\n",
        "\n",
        "result=chain({'query':user_input})\n",
        "print(f\"Answer:{result['result']}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llm_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
